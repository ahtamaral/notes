# Programação

# Mercado de TI

- A intenção da série não é pra ser uma receita de bolo

**Mercado de TI em geral**

- Altamente competitivo
- ANos no mesmo emprego não tem muito valor, mas sim a capacidade de resolver problemas
- O fato de ser um mercado pouco regulamentado é que quem realmente é bom avança. Os acomodados ficam pra trás. Código é código → Ou vc resolve o problema melhor que os outros ou alguém vai resolver melhor que você.
- Não importa se você acha que vale mais, você normalmente ganha o que merece.
- Por isso sempre foi um terreno fértil, pois não se liga no status quo.
- É problema seu se não percebe as centenas de oportunidades que existem, não só fora do emprego, mas dentro. Se você acha que pode fazer melhor que o seu empregador, cadê você abrindo sua própria empresa? Não existe certificação nem orgão regulador pra te segurar. Não existe me pague primeiro, faça depois.
- Cada empresa organiza seu setor de tecnologia como quiser. Não adianta copiar o que outros fazem. É preciso analisar o histórico de resultados reais, não o que aparece em comerciais e marketing.
- Não seja arrogante achando que sabe tudo. Principalmente em início de carreira, você não sabe é nada. Dentro de 5 anos você talvez entenda a dinâmica do mercado como um todo. É muito fácil ter conclusões precipitadas baseadas no próprio umbigo.
- Programação não é uma profissão de procedimento, mas sim uma profissão de **prática**.
- Os critérios pra projetos e **empresas públicas** são atrasados e ineficientes, nãodevem seguir de referência no mundo real.
- Akita sempre pode dar um passo pra trás pra dar 2 pra frente. Aceitava ganhar menos num emprego que ele não tinha experiência, mas com confiança de que compensaria rápido o ganho. Não existe caminho de carreira certo.
- Se você for devagar, inseguro e ineficiente, nunca vai sair do lugar.
- Dentro da indústria, existem diversos tipos de empresa. Vai ser um panorama geral do ponto de vista do Akita.
- **Empresas públicas:** No Brasil, sempre é uma opção para quem é inseguro demais e precisa mortalmente de garantias.
    - Concorrência desleal, inibemo crescimento de empresas de verdade na região e politicagem vale mais do que mérito. Você precisa de um diploma pra se enquadrar.
- **Empresas de grande porte (enterprise)**: Marcas reconhecidas, mais de 1/2mil funcionários, onde você será só mais um, engajar em hierarquia rígida e provavelmente bastante viciada em politicagem.
    - Os progamadores normalmente ficam responsáveis pela manutenção de sistemas de **"back-office"**, sistemas que ficam por trás dos processos de outros setores da empresa (financeiro, compras, RH, atendimento ao cliente, etc).
    - Você pode passar a vida inteira escrevendo relatórios, ajustando regra de negócio nova, atendendo uma nova legislação ou formulário. Isso não é necessariamente ruim, é até recomendável você conhecer uma dessas por dentro. Mas tomar cuidado pra não ficar muito tempo e acabar defasado.
    - Aqui você encontra empresas de todas as indústrias. (Sistema administrativo de hospital, fábrica automotiva, setor agrícola, comércio exterior, etc).
    - Se você precisa de alguma estrutura ao seu redor, pode ser um bom começo.
- **Empresa de "produto"**: São as empresas cujo core business é o software. Aplicativos, fintechs, e-commerces, etc. Algumas das grandes empresas criaram divisões e departamentos mais ágeis pra inovar, atrair talentos e se manter competitivas (LuizaLabs, Itaú Cubo, etc). Assim como a anterior, se você precisa de alguma estrutura, pode ser um bom começo.
- **Outsorcing/Terceirizadas**: Meio uma zona, mas com **três subcategorias**.
    - **Agências**: Muitas empresas que precisam ser mais ágeis ou não sabem lidar com tecnologia contratam agência. Seja pra manter seus websites ou e-commerces. Geralmente softwares white-label. Geralmente um bom lugarpra iniciantes mais arrojados. São lugares que vendem mal, por isso pagam mal, e você vai fazer muitas horas extras. Mas é importante vivenciar pra aprender a ter jogo de cintura. É muito fácil se acostumar mesmo num lugar desses.
    - **Body-shops**: Empresa física ou remota que aloca você por projeto (não te contrata em tmepo integral) e não dá o suporte minimo, ou demite se ficar muito tempo sem projeto. Muitas te contratam por um número mínimo de horas, e você preenche uma planilha e é pago por hora. A função dessas empresas é achar pessoas no mercado, manter um banco de currículos, e quando os clientes precisam de algum perfil, rola um match. Fortemente desaconselhado para iniciantes. Ainda não está preparado. PRecisa de outras pessoas ao redor pra crescer. Esse tipo de empresa é bom pra quem se garante e sabe se vender sozinho. Bom pra home-office ou pra cobrar mais caro para um cliente sem ter vínculo empregatício com uma empresa maior. Funciona bem pra quem já tem experiência. Mas quem **vira freelancer rápido demais perde muitas oportunidades de crescer antes do tempo.** Você perde muito tempo preocupado se haverá um próximo projeto, e não há ninguém para te orientar. No começo pode parecer que você ganha mais, mas você não cresce, é uma armadilha.
    - **Consultorias (ou Fábricas de software)**: Vivem de reputação, costumam ter uma formação inical, acompanhamento com o cliente. Grande vantagem, você vai ter suporte da empresa e de seus pares, além da oportunidade de trabalhar com diversos tipos de clientes e projetos. Elas vendem um processo mais estruturado de produção de software, com menos margem para autonomia, mas para iniciantes geralmente vale a pena, já que oferecem algum treinamento e segurança.
- Não ache que você vai aprender tudo só no trabalho. ENtrar no ritmo de aprender enquanto faz, você vai andar muito devagar. Os primeiros empregos devem servir pra você aplicar a parte técnica aprendida na teoria de livros e cursos e aprender os protocolos de comunicação. Como conversar com seus pares, com seu chefe, com seu cliente, e entender as expectativas de cada um, como você pode mostrar resultados práticos e eficientes.
- **Um programador não é definido pelas tecnologias que sabe nem por quanto ganha**. Se você acha que ganha pouco mas sabe que é bom e aprende rápido, isso é temporário. **Um programador é definido pela eficiência com que consegue resolver problemas reais.**
- Dê preferência à empresas que te contratam do jeito certo. Saiba identificar quando uma empresa te oferece PJ só pra pagar menos ou pra te repassar mais. Na dúvida, dê preferencia a quem contrata CLT cheio.
- Quando você sair de uma empresa, seja ético: Avise com antecedência, cumpra seu aviso prévio. Coisas básicas que todo profissional deveria saber.
- Para um iniciante de 20 anos, seu currículo não vai se destacar muito mesmo. Qualquer oportunidade é melhor do que nada, não tem muito jeito. Mas você precisa adicionar coisas que outros não tenham, como fluência em inglês. Você precisa arranjar algum jeito de se destacar na multidão. Vá até as empresas, não fique passivamente esperando alguém te ligar.
- **Entenda que o mercado de trabalho tem excesso de programador iniciante e falta de programador realmente bom**. Existe uma saturação de gente que customiza e-commerce, que se diz front-end, freelancers que não são tão bons. Todo mundo saiu da faculdade sabendo algum Java ou .Net. No início de carreira você estará no bolo de baixo,onde tem mais gente, onde a reputação é a mais baixa, e onde se paga pior. Por isso iniciantes não devem se preocupar com salário, por que realmente tanto faz.
- Mas você precisa sim sair do bolo da maioria e subir para o topo de profissionais escassos, onde as empresas lutam por você, oferecendo valores maiores. Você precisa passar por várias empresas das camadas mais baixas, e ir acumulando boas referencias e experiencias e **networking de verdade.**
- Networking não é sacanagem de linkedin. Networking de verdade começa no seu emprego, no seu projeto. Você constantemente e consistentemente ao longo do tempo demonstrando capacidade de resolver problemas. Até as pessoas dependerem das suas habilidades, contar contigo. Quando seus pares sairem de onde vocês estão, eles lembrarão de vocês em outro lugar. O estagiário de hoje pode ser o diretor de amanhã. Isso é networking: Acesso a pessoas de influência por que eles confiam em você, não por que você os adicionou no Linkedin.
- Não pense em salário nos primeiros anos. É inútil. A não ser que você pretenda ficar na camada baixa. Pensa em estudar sem parar, pra subir ao topo. No começo você estará onde a maioria está, não tem jeito, **mas deixe-os pra trás o quanto antes.** Não se conforme por muito tempo. Não acostume com validação. Seja esperto onde está mais escasso.
- Quem tem paciência, estuda, fica quieto e ouve, faz mais do que fala, e não liga pro que os outros ficam julgando, tende a ter um começo mais difícil. Mas seu crescimento lá na frente é exponencial.

# Conhecimentos básicos

- [https://www.akitaonrails.com/2019/02/06/akitando-38-conhecimentos-basicos-para-iniciantes-em-programacao-serie-comecando-aos-40](https://www.akitaonrails.com/2019/02/06/akitando-38-conhecimentos-basicos-para-iniciantes-em-programacao-serie-comecando-aos-40)

# Front-end

- URL → protocolo/Dominio/caminho_do_arquivo
- Você envia o domínio que quer acessar para o DNS, e ele o converte em um endereço IP, e te conecta a essa máquina, que lhe envia os arquivos web que você requisitou
- Listar o final da URL com o caminho direto do arquivo é falho, pois dá oportunidade para um atacante tentar vasculhar a máquina do usuário e acessa arquivos que inicialmente não seriam servidos para o cliente. Por isso hoje é comum ver a parte final da URL como um código criptográfico.
- Navegador → Programa cliente de TCP → Recebe um arquivo HTML e traduz as marcações para elementos visuais.
- Na marcação existe o conceito de hipertextos, que são texto que possuem referências para outros textos (i.e. outros documentos html).
- No começo, não se importa muito com estilo, mas apenas disponibilizar textos interligados com outros textos. Essa é a World Wide Web.
- Com o passar do tempo, foi possível não só pedir arquivos texto (html) para o servidor, mas também pedir binários que rodariam do lado do cliente, e dessa forma surgiu a primeira geração de páginas web dinâmicas, que alteravam-se conforme a funcionalidade implementada.
- Os primeiros sites dinâmicos eram feitos com binários em C, e o padrão foi chamado de Common Gateway Interface (CGI).
- Mas usar C para interagir com HTML era desproporcionalmente dificil. Nesse contexto surge uma linguagem muito mais adequada para manipular longas cadeias de caracteres (strings), que era o PERL, que trazia uma sublinguagem chamada regular expressions (RegEx), pra manipular strings. → **Obrigatório estudar!**
- Servidor web famoso, por facilidade de uso e open-source → **Apache.**
- No início da web, pra fazer um site com visual, digamos, 10 páginas, você precisaria ter 10 arquivos HTML com os mesmas marcações para definir seu estilo, e alterar seu conteúdo interno. Se depois você quisesse alterar o layout do site, você deveria alterar os 10 arquivos html, um a um. Isso se deve por que HTML inicialmente não tinha como propósito ditar o estilo visual de uma página. A ideia era que cada navegador apresentaria o conteúdo que recebesse. HTML era apenas marcação de conteúdo.
- Com o surgimento do CSS, separamos estilo do conteúdo.
- Nesse contexto, Internet Explorer saiu na frente pois implementava melhor as primeiras versões do CSS, no que chamamos de guerra dos navegadores (Nerscape vs Internet Explorer).
- Com os scripts que dinamicamente alteram o html, surgem as possibilidades de estilização da página web e  profissão de web designer.
- Dado que linguagens no servidor (Na época, C e PERL) podiam ter acesso a recursos e interação com bancos de dados, surge o conceito de **aplicações web,** não apenas o desenvolvimento de sites. → "E se eu pudesse fazer um formulário em que o usuário insere o número do seu cartão de crédito e enviar para o script PERL no servidor e salvá-lo no banco de dados?" → Início da semente para produtos como e-commerces.
- Em paralelo a PERL e às CGI's nasceu outra forma de criar páginas web dinâmicas, em que o script que processava informção e cuspia html era interno ao próprio servidor (Apache ou IIS), e **não mais chamava um programa externo**, com o crescimento de novas linguagens para esse fim (PHP vs. ASP),  e o início da briga server-side, pela hegemonia do servidor. **O próprio servidor web ganhou a capacidade de interpretar lógica de programação e cuspir HTML.** O principal proponente desse método foi o PHP. Nessa época que também cresceu o Java como linguagem back-end.

![Programac%CC%A7a%CC%83o%20b4658eb9742a4036864f144813e52191/Untitled.png](Programac%CC%A7a%CC%83o%20b4658eb9742a4036864f144813e52191/Untitled.png)

- Surgem os **servidores de aplicação:** Sua função é executar os programas que cospem HTML. Todo servidor de aplicação é um servidor web, mas a recíproca não é verdadeira. A função dos servidores web é fornecer páginas HTML.
- Conforme ficou mais claro que era possível programar aplicações interativas, controlar o visual se tornou mais importante. A evolução do CSS1 p/ CSS2 e seu modelo tableless (transição do site como uma grande tabela para o atual modelo de caixas) tornou as páginas web muito mais fluidas.
- Nessa época surge uma tecnologia inaugurada pela Mozilla (Antiga Netscape) chamada Asynchronous Javascript (AJAX), que tornou possível o Gmail, em 2004. Esta aplicação foi revolucionária pois abriu a perspectiva de que se um cliente quiser rodar uma determinado programa, ele não precisa mais estar vinculado ao seu sistema operacional, pois seria possível acessá-las através do navegador, independente do SO utilizado. Esta mudança de paradigma preocupou a Microsoft que mantinha seu monopólio de programas por conta de seu vínculo com o Windows, como o pacote Office e o cliente de e-mail Outlook.
- **Ponto da história: 2004** → HTML4, CSS2 e XML como formato para estruturação de dados.
    - HTML é especializado em estruturar conteúdo de texto, já o XML, dados mais diversos, como cadastros.
    - CSS2 introduziu web fonts, internacionalização e posicionamento relativo e absoluto na tela.
    - CSS é um linguagem declarativa, onde você declara regras visuais que são aplicada no HTML, e são cascateadas, onde um regra herda as características da regra pai.
    - Não mais a web baseava-se em simples sites de conteúdo hipertexto, mas havia evoluido para aplicações que gerenciavam conteúdo, surgindo clientes de e-mail na web, e-commerces e redes sociais. **Abriu-se uma nova fase de desenvolvimento.**
- Paralelamente, no mundo Java, popularizou-se o conceito de frameworks → Mais do que uma linguagem, eles fornecem uma estrutura pré-definida pra ajudar a desenvolver os aplicativos, fornecendo funcionalidades como segurança, validação de dados, autenticação e autorização granular, templates visuais.
- Surgimento do Ruby on Rails e inauguração da era dos frameworks que herdam os conceitos de agilidade **(manifesto ágil de 2001).**
- Surgem os frameworks Javascript que homogeinizam o desenvolvimento para todos os navegadores, em vez do programador ter que especificar o código para cada um.
    - Surgem a **primeira geração** de microframeworks especializados em visual do lado do navegador, como o **jQuery.**
- **2007** → Começa a revolução dos smartphones com o lançamento do primeiro iphone. Surge o problema do desenvolvimento mobile, cuja resolução é muito diferente dos monitores que já existiam.
- No meio dos anos 90 houve a tentativa de rodar Java na web, mas que a princípio não seria seguro por conta da linguagem ser geral e dar possibilidade para um atacante acessar arquivos da máquina  de outro. Então foi desenvolvida uma tecnologia de container para rodar Java com baixo privilégio (sem permissões de administrador), o que permitiu executar código Java no navegador, surgindo os **applets Java**. Esta inovação permitia criar visuais e animações altamente dinâmicos, impossíveis de serem feitas apenas com HTML/CSS. Sucessor dessa tecnologia foi o famoso **Flash**.
- Porém Flash apresentava muitos problemas de segurança e era extremamente pesado pra rodar em smartphones, até que Steve Jobs escreveu uma carta aberta contra o Flash, o que provocou a sua morte.
- Porém, ainda existia muita necessidade de se desenvolver tecnologia para exibição de vídeos e animações.
- Essa conjuntura levou a W3C a acelerar uma coisa que estava há muitos anos atrasada. Em 2014 ela lançou a última geração de front-end, a tríade HTML5/CSS3/Javascript.
- Nesse meio tempo (2008-2014), o desenvolvimento front-end era muito complicado, pois não havia padronização entre navegadores, quando o jQuery se tornou uma necessidade.
- Com o fim do Flash, Javascript voltou a ser a única opção viável para animação e interação. Uma linguagem extremamente ruim e desatualizada desde os anos 2000.
- Surge CoffeScript, uma linguagem escrita em Ruby, cuja compilação produzia código JavaScript, evitando uma série de infortúnios desta linguagem na época. Muitos conceitos úteis do CoffeScript foram herdados pelo ECMAScript6, lançado em 2015, tornando aquele obsoleto.
- Essas inovações em HTML5/CSS3 permitiram o chamado design responsivo, onde, independente do tela (celular, tablet, PC), os conteúdos da página se adequam dinamicamente
- Surgem as bibliotecas de estilo reusáveis, como frameworks de CSS, como o Bootstrap. Este evita evitar a roda, e cria elementos novos como o hamburguinho pra menu, etc.
- Com tantos novos elementos, surgiu uma nova necessidade. Não era só escrever HTML e linkar o CSS. Agora o desenvolvimento web necessitava de muitos e muitos assets (frameworks, bibliotecas, códigos de google analytics). Seria insuportável ficar indo de site em site e baixando e descompactando e instalando cada um deles. No mundo Javascript surge o **npm**, e mais tarde o yarn. Estes programas gerenciam os assets no lado da máquina do desenvolvedor.
- Contudo, com todos esses assets, a troca de dados entre servidor e cliente se tornava muito mais custosa, ainda mais nessa época (+- 2010), onde no máximo tinha-se a geração 2G de celulares. → minificação.
- Evoluindo em cima da herança do Gmail, o AJAX não era suficiente, então experimentou-se tirar a lógica do servidor de aplicação e transferir o controle do estado da aplicação apra mais próximo da tela gráfica. Assim surgem os frameworks Javascript. → Angular, React, Vue.

# Back-end (parte 1)

**Receita: Na dúvida, procure o contexto do porque certa tecnologia foi criada.**

**Objetivo da seção:** Contextualizar as tecnologias back-end.

Você não precisa ter a melhor máquina para trabalhar, tem que saber dominar a máquina que tem, extrair o máximo dos recursos dela.

O hardware vem da fábrica podendo receber certas instruções (funções com argumentos, da CPU). Ela executa essa instrução e grava noutro registrador a resposta. A linguagem que usa-se para falar diretamente com a máquina é o Assembly. Além do hardware, existem as instruções para o sistema operacional, as chamadas syscall. Binários são instruções p/ máquina e sistema operacional (Que é uma abstração para a máquina).

Escrever código em Assembly não tem uma performance melhor! Outro problema é que o código depende diretamente da arquitetatura da sua CPU, por isso existe C, que é uma linguagem que unifica instruções para diferentes CPU's, novamente abstraindo a máquina.

O C cria um binário nativo, que depende diretamente de chamar instruções da máquina e do SO.

O compilador não apenas traduz o seu código: Ele o otimiza. → É literalmente mágica, sendo assim, seu principal objetivo deve ser escrever código que possa ser lido por outra pessoa. É tarefa do compilador otimizá-lo para a máquina.

**Linker (linkeditor):** Liga seu binário às bibiliotecas, que podem ser **estáticas ou dinâmicas**. 

**Estática:** Une os binários em um mega binário. Pode ser levado para outra máquina sem se preocupar com dependências.

**Dinâmica:** Uso dos arquivos header. Dessa forma, os programas vão reutilizar o mesmo binário. As bibliotecas devem ser baixadas manualmente para uso, bem como seu caminho na máquina deve estar especificado numa variavel de ambiente.

**Ex: Linguagem Go** utiliza linkagem estática. Baixa o código fonte das dependencias, compila e gera um binário único. Dessa forma você pode desenvolver um código na sua máquina, compilar num servidor e não ter que se preocupar muito com instalar dependencias.

**Por quê não compilar tudo estaticamente?** 1- Você não precisa ter o código fonte no seu projeto, só o header. 2.1- Existe uma cópia da bibilioteca para cada progrma que a utiliza. Ineficiente em termos de disco. 2.2- Se tiver um problema na biblioteca, só é necessário recompilá-la, e todos os clientes já estão atualizados. 

Programação é muito isso: Fazer escolhas, que nem sempre estão erradas. Acostume-se.

**Gerenciador de pacotes(Conceito Linux)**: (RedHat, CentOS) Yum, (Debian, Ubuntu) apt, (Arch, Manjaro) pacman.

Quando não existe o pacote do programa que quer, baixa-se um tarball.

**./configure** → Checa se você tem todas as dependencias para compilar o programa baixado.

**make** → Lê um arquivo chamado makefile, que declara tarefas a serem executadas, geralmente relacionadas a compilação.

**sudo make install →**Roda a tarefa install do makefile, que dá permissões de execução ao binário e mover para um diretório que o PATH consiga achar.

**Obs:** **Make vs Shell Script** → Make é um programa especialista, feito para entender as dependências entre os arquivos do seu programa e recompilar só o que é necessário, bem como é uma linguagem declarativa, sendo mais fácil adicionar novas tarefas, sem preocupar-se muito com estruturação do código. Fazer essas funcionalidades em shell script demandaria um esforço desnecessário por parte do programador.

**Make vs Cmake** → Makefile é um buildsystem. Cmake é um gerador de buildsystems. Ele gera instruções de compilação mais independentes de plataforma e versão, bem como pode utilizar diferentes build systems, como Makefiles e Ninja.

No outro lado do espectro, temos as linguagens **interpretadas.**

**Interpretador**→ É um programa que lê código escrito e o traduz para a máquina sem a necessidade de gerar um código nativo. Ele tem que traduzir o código toda vez que carrega. É um programa de linha de comando que recebe o caminho para o arquivo texto com código que ele vai traduzir.( Arquivos pré-parseados file.pyc → Economiza tempo da etapa de parsing).

Antigamente a ideia desses programas era escrever programas de linha de comando de **execução muito rápida.** A primeira linha é um shebang **(#!/bin/bash)**.

**Um pouco sobre servidores**

Quando você executa algo em linux, o código é carregado na memória na forma de um processo. Para servir múltiplos clientes TCP ao mesmo tempo, o mais fácil é criar um fork do processo atual, que é bastante barato, usando a técnica Copy on write, pois ele reutiliza bits do processo original. Dessa forma, se o processo original ocupa 512 kB, após o fork, os processos usarão menos que 1 mB.

O Apache antigo só usava fork. Depois ganhou a capacidade de executar programas dependendo da URL pedida, no padrão conhecido como CGI.  Inicialmente esses programas era executáveis em C, mas rapidamente fizeram Perl funcionar no Apache e começamos a era da Web dinâmica (Lembrar que Perl era muito forte por suas expressões regulares, que facilitava a geração de HTML dinâmico).

**Problema de carregar interpretadores a cada nova requisição** → Quando as operações do progrma começam a complexificar, como acessar bancos de dados,XXXXXXX.

Programas que compilam e rodam em dois SO's diferentes não necessariamente rodam igual neles. Coisas feitas para Windows rodam bem em Windows, e o mesmo para Linux. Por conta disso, somos obrigados a usar threads, que são linhas de execução paralelas dentro de um mesmo código/processos.

**Dilema: Programação baseada em processos com fork ou um processo com múltiplas threads?**

Hoje em dia é muito mais comum o uso de threads, mas forks não estão obsoletos. O conector do Postgres usa-os, por exemplo. O problema é que a memória das threads não é isolada entre si. Escrever programa multi-thread é uma puta dor de cabeça, pois deve se garantir thread safety. Uma thread não pode pisar na memória de outra thread. A forma mais comum de resolver isso é: Quando uma thread vai escrever em memória, ela primeiro avisa ao sistema que irá fazê-lo, e pega o que nós chamamos de lock, que impede que outras threads escrevam naquela área também, e, após a escrita, libera-o. Se falhar em pegar o lock, memória pode ser sobrescrita. Se falhar em largar o lock, gera um deadlock, bloqueando acesso a outras. **Programação multithreading, gerenciamento de memória e segurança** → Os passos mais difíceis de entender e dominar.

**Contexto para o surgimento do Java**

Java embute conceitos de compiladores e interpretadores, mais especificamente máquinas virtuais - A **Java Virtual Machine (JVM):** Evolução de interpretador. Ao invés de ler o código em uma linguagem, ele que abstrair o sistema operacional por baixo. Para o programa em Java não existe o Linux ou Windows, apenas a JVM. Gera um bytecode. que é o conjunto de instruções para a JVM, um binário nativo desta.  Java nunca vai substituir um Perl como programa de linha de comando, pois sua inicialização á muito pesada, até hoje. Em parte, por que seu gerenciador de memória (Garbage collector) é muito sofisticado. 

C fornece portabilidade, desde que você recompile o código. O passo que Java dá além é que o código nem precisa ser recompilado, pois as diferentes JVMs para cada SO sabem traduzir o binário intermediário (bytecode) para binário nativo.

Interpretadores dependem bastante do SO embaixo. 

# Back-end (parte 2)

[Notebook](Programac%CC%A7a%CC%83o%20b4658eb9742a4036864f144813e52191/Notebook%205b596d1cf37b4920858c061e221e40a0.md)

Umas das coisas mais importantes saber é que você nunca vai escrever código 100% do zero. Você vai ser obrigado a utilizar bibliotecas dos outros. Nesse episódio, vamos entrar no contexto das bibliotecas dinâmicas e ver o quão fundo vão.

Até esse ponto tinhamos linguagem como Java com fortes influencias de C++, orientação a objetos e com a existencia da JVM. Akita argumenta que Java é mais um linguagem orientada a classes. 

Bibliotecas são um conjunto de funções que fazem determinadas coisas úteis e podem ser reutilizadas. Componentes são funcionalidades, uma biblioteca pode ter vários componentes. P. ex. a funcionalidade de interface gráfica de um calendário é um componente, seu gerenciador de datas é outro. Com o surgimento de computadores com sistemas de janelas, foi tornando-se comum a modelagem de componentes como classes e objetos, quando esses conceitos começaram a se mesclar -> Conceito de componentização. Torna mais fácil produzir, reusar e comercializar software.

Com o avanço da sofisticação dos ambietes gráficos, não era possível o programador ter que programar todo botão do zero. Por isso tornou-se comum as linguagens já terem suas bibliotecas (DLL) padrão com esses componentes disponíveis para os programadores. 

Essas bibliotecas forneciam classe com interfaces para o código que as consumia, permitindo a sofisticação dos aplicativos desktop em ambientes gráficos. Nesta época todas as aplicações eram basicamente o binário do aplicativo e um arquivo de banco de dados, no estilo DBF (DataBase File).

Bancos de dados primitivos eram muito simples, apenas uma estrutura de dados interligada com um índice raiz, tudo num mesmo arquivo. Quando as empresas possuiam 1 computador pra tudo, até funcionava, mas com a popularização de PC’s e tecnologias de rede local, o acesso compartilhado ao banco se tornou necessário, assim surgiu o conceito de aplicativos distribuídos. Os dados do banco então pertencem então a um sistema de arquivos compartilhado, em que todos podem ter acesso. Isso cria o problema das condições de corrida. Nessa época, a única solução era travar o banco de dados inteiro quando alguém fosse consumir suas informações. 

A solução do banco de dados como arquivo compartilhado na rede não é suficiente, pois entram muitas variáveis que podem atrapalhar, como dar pau no programa, na rede, engasgamento do servidor, etc. Logo, se popularizaram os servidores de bancos de dados. Agora a diferença é que em vez do cliente abrir o arquivo na rede, ele se conecta a um programa que está remoto, num servidor, e este é quem faz as alterações na máquina própria máquina. Isso evita que os arquivos se corrompam tão fácil, o servidor de banco de dados é um mediador, só ele abre e escreve os arquivos.

O banco do servidor possui duas etapas: Processamento para lógica de negócio e gerenciamento dos dados em si, além da existência de bancos cliente. Esse modelo ficou conhecido como bancos three-tier, que é quando as soluções corporativas começam a se encaixar. 

Com a ideia de um servidor de aplicação, passou-se a pensar mais em interoperabilidade e protocolos de rede. Isso junto às ideias de componentização, orientação a objetos e chamada a lógicas de negócios em outro servidor -> Chamadas de procedimento remoto.

 Assim como o header fornece uma interface indicando quais serviços são oferecidos pelo binário da biblioteca, mas agora em vez de uma biblioteca dinamica é uma biblioteca remota, um cliente de um serviço remoto. Não temos como saber que tipos de funções um servidor de aplicação oferece, por isso precisamos de uma interface, contendo as funções, os argumentos, resultado etc. 



	O java foi uma das primeiras linguagens a oferecer recursos para implementar a arquitetura 3-tier bem feita, por isso tornou-se famoso no mundo corporativo, bem como a linguagem XML, usada nos protocolos de comunicação entre as camadas.
Nessa época surge a UML, p/ descrever sistemas orientados a objetos muito grandes, bem como outras metodologias de engenharia de software, como Design patterns. O mundo de TI corporativo começa aqui no fim dos anos 90, com o J2EE e as metodologias clássicas de eng. de software orientada a objetos.
Paralelamente evoluia o C#, que era meio que uma alternativa da Microsoft para orientação a objetos no mundo Windows. Conseguiu não ser uma cópia do Java.
	
	No mundo Linux, Perl era uma linguagem famosa p/ scripts de administração de sistema, que aos poucos foi sendo substituida por Python, que era mais limpa e moderna.
	PHP, com sintaxe mais fácil do que Perl, acabou dominando os servidores de aplicação, junto com o novato mySQL, formando a stack LAMP. Mas o interpretador do PHP era muito ruim, cheio de erros de segurança, e a bolha das .com impulsionou a preocupação com segurança e parou-se de pensar em novas linguagens.
Depois da bolha das ponto com, surge o manifesto ágil, que fornece uma metodologia que ajuda muito o mundo open source a crescer, e bater de frente com o mundo corporativo. Surgem linguagens como Ruby que permitem desenhar aplicações web que antes só eram possíveis com Java e servidores de aplicação do mundo corporativo, fazendo os caras tremerem na base.
Linguagens imperativas x funcionais -> Lambdas e meta-programação. Conceitos resgatados lá da década de 50 pelos programadores de cabelo branco.
Agora performance não era o único critério para escolher uma linguagem (Lei de Moore), mas sim suas funcionalidades também!
Erlang é como Java, tem tipo uma JVM, mas utiliza lambda calculus e orietanção a objetos, mas sem ser nenhum dos dois. É o chamado Actor Model. Atores possuem estado encapsulado e se comunicam por mensagens. Além de bootar o kernel, ele possuem alguns “daemons” p/ gerenciar os atores. Java e Erlang basicamente montam sistemas operacionais inteiros p/ funcionarem, ao contrário das linguagens interpretadas (Perl, Python e Ruby), cujo objetivo é começar rápido e terminar rápido. Erlang e Java funcionam melhor se você ligar e deixar ele parasitar máquina toda. A ideia é iniciar um único processo de Erlang e deixar ele se gerenciar eternamente, o que garante confiabilidade: Ficar de pé eternamente é o propósito e o maior desafio.
Você como programador sempre vai ter que se preocupar com gerenciamento de dependências e suas versões.
Listar as dependências do seu projeto e atualizá-las sem quebrar, é parte fundamental p/ a programação.
Erlang foi desenvolvido p/ setor de telecomunicações.
Elixir foi uma tentativa de não copiar o Ruby e criar uma sintaxe moderna em cima da VM do Erlang, beneficiando-se de suas vantagens.
Concorrência e paralelismo (parte 1)
Recapitulando -> Explicou conceitos básicos de OS e compilação e bibliotecas estáticas e dinâmicas. Máquinas virtuais e interpretadores.
Esse assunto só se aprende na prática.
Hoje em dia todo mundo tem um computador potente. Processadores de servidor vai até 24 cores. Sendo que a Intel possui a tecnologia HyperThread, fazendo com que 1 core enxergue duas Threads. Isso é muito paralelismo.
 GPU da Nvidia 2080 possui 2444 CUDA cores, sendo que algumas placas mães suportam duas dela. Como fazer um processamento tao massivamente paralelo funcionar?
O mundo digital que experimentamos hoje é massivamente paralelo. Mas não foi sempre assim. Acesso a esse mundo paralelo p/ os programadores existe há pouco mais de uma década.
Nos anos 50, os computadores eram extremamente lentos e só processavam os “jobs” em um “batch” que é uma fila.

